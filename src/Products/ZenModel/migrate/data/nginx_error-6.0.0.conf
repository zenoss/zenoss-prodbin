# nginx error logs

grok {
    # Matches messages like the messages below:
    # 2017/08/30 20:17:37 [error] 85#0: *41 upstream prematurely closed connection while reading response header from upstream, client: 172.17.42.1, server: , request: "HEAD /ping/status/performance HTTP/1.1", upstream: "http://127.0.0.1:8888/ping/status", host: "localhost:8080"
    # 2017/08/31 14:58:09 [notice] 4802#0: signal process started
    # request: "GET /ws/metrics/store HTTP/1.1"
    # upstream: "http://127.0.0.1:8443/ws/metrics/store"

    match => { "message" => [
        "^(?<datetime>%{YEAR}[./-]%{MONTHNUM}[./-]%{MONTHDAY}[- ]%{TIME}) \[%{LOGLEVEL:loglevel}\] %{POSINT:pid}#%{NUMBER:tid}: %{DATA:message}",
        "request: \"%{WORD:method} %{URIPATH:request} %{WORD}\/%{NUMBER}\"",
        "upstream: \"%{URI:upstream}\""
    ]}
    break_on_match => false
}

# Elasticsearch doesn't like the format of datetime.
# This filter parses the datetime field into a time value,
# removes the datetime field from the data, and
# then uses the parsed value as the "@timestamp" for the message.
date {
    match => [ "datetime", "YYYY/MM/dd HH:mm:ss" ]
    remove_field => ["datetime"]
}

mutate {
    gsub => [ "loglevel", "debug", "DEBUG" ]
    gsub => [ "loglevel", "info", "INFO" ]
    gsub => [ "loglevel", "notice", "INFO" ]
    gsub => [ "loglevel", "warn", "WARN" ]
    gsub => [ "loglevel", "alert", "WARN" ]
    gsub => [ "loglevel", "error", "ERROR" ]
    gsub => [ "loglevel", "crit", "ERROR" ]
    gsub => [ "loglevel", "emerg", "FATAL" ]
}
